CL-4 1

import pandas as pd import
numpy as np
from sklearn.model_selection import train_test_split from
sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error. r2_score import
matplotlib.pyplot as plt
# Load the dataset
df = pd.read_csv('USA_Housing.csv') # Explore the dataset print(df.head()) print(df.info())
# Handle missing values if any df = df.dropna()

# Select relevant features and target variable
X = df[['Avg. Area Income', 'Avg. Area House Age', 'Avg. Area Number of Rooms', 'Avg. Area Number of Bedrooms', 'Area Population']]
y = df['Price']

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize the Linear Regression model model = LinearRegression()
# Train the model model.fit(X_train, y_train)

# Make predictions on the test set y_pred = model.predict(X_test)

# Evaluate the model performance
mse = mean_squared_error(y_test, y_pred) r2 = r2_score(y_test, y_pred)

print(f'Mean Squared Error: {mse}') print(f'R-squared: {r2}')


CL-4 3

import tensorflow as tf
from tensorflow.keras.datasets import imdb from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Dense
from tensorflow.keras.preprocessing.sequence import pad_sequences
# Set the parameters
max_features = 10000 # Number of words to consider as features
maxlen = 100 # Cut texts after this number of words (among top max_features most common words) batch_size = 32
# Load the IMDB dataset
(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features) # Pad sequences to have a consistent length for the input to the RNN
x_train = pad_sequences(x_train, maxlen=maxlen) x_test = pad_sequences(x_test, maxlen=maxlen)

# Build the RNN model with LSTM model = Sequential()
model.add(Embedding(max_features, 128)) model.add(LSTM(64, dropout=0.2, recurrent_dropout=0.2)) model.add(Dense(1, activation='sigmoid'))

# Compile the model model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

# Train the model model.fit(x_train, y_train, batch_size=batch_size, epochs=5, validation_data=(x_test, y_test))

# Evaluate the model
score, acc = model.evaluate(x_test, y_test, batch_size=batch_size) print(f'Test score:
{score}')
print(f'Test accuracy: {acc}')


